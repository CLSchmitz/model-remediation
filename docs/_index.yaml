# Copyright 2020 Google LLC.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

book_path: /responsible_ai/_book.yaml
project_path: /responsible_ai/_project.yaml
title: Model Remediation
landing_page:
  custom_css_path: /site-assets/css/style.css
  nav: left
  meta_tags:
  - name: description
    content: >
      MinDiff techniques for model remediation
  rows:
  - classname: devsite-landing-row-100
  - heading: What is Model Remediation?
    options:
    - description-100
    items:
    - description: >
        <p>
        After performing disaggregated evaluation of a machine learning modelâ€™s performance, you
        might notice that your model is underperforming across certain slices of data. If left
        unaddressed, this type of inequitable performance can lead to unfair outcomes. In practice,
        there are two main classes of technical interventions for addressing this type of bias
        concern:
        <ul style="padding-left: 20px">
          <li>
              Augmenting the training data by collecting more examples, generating synthetic
              data, or adjusting the weights and sampling rates of different slices of data
          </li>
          <li>
              Introducing loss functions, or constraints to remediate the model itself
          </li>
        </ul>
        </p>

    - code_block: |
          <pre class = "prettyprint">
          import tensorflow as tf
          import responsible-ai

          # This is a short code snippet that shows off your project.
          # Launch a Colab notebook to run this example.
          print("Hello, responsible-ai")
          </pre>
          {% dynamic if request.tld != 'cn' %}
              <a class="colab-button" target="_blank"
               href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tu
               torials
               /_index.ipynb">Run in a <span>Notebook</span></a>
          {% dynamic endif %}

  - classname: devsite-landing-row-100
  - heading: What is MinDiff?
    options:
    - description-100
    items:
    - classname: devsite-landing-row-100
      description: >
        <p>
        MinDiff is a technique which applies a loss function that seeks to balance error rates
        across different slices of your data by penalizing disparities in performance across the
        desired metric. Typically, you apply MinDiff when trying to minimize the difference in
        either False Positive Rate (FPR) or False Negative Rate (FNR) for a slice of training data
        that belongs to a sensitive class when compared to the rest of the dataset.
        </p>

  - classname: devsite-landing-row-100
  - heading: How does MinDiff work?
    options:
    - description-100
    items:
    - classname: devsite-landing-row-100
      description: >
        <p>
        Given two sets of examples from a dataset that are split across a sensitive attribute,
        MinDiff penalizes the model during training for any differences in the distribution of
        scores between the two sets. The lower the difference, the lower the penalty applied.
        The penalty is applied by adding a component to the loss which the model is training on, and
        can be thought of as a measurement of the difference in distributions. The model learns from
        the penalty and adjusts the distributions, causing them to converge.
        </p>
        <figure>
        <img src="images/mindiff.png"
        <p>
        Because this effectively adds an objective for the model to optimize over, this may come
        with tradeoffs with respect to performance on the original task. In practice, MinDiff has
        been found to be effective while not degrading model performance beyond product needs.
        For examples showing how to implement MinDiff, see the docs <a href= "">here</a>.
        </p>

  - classname: devsite-landing-row-100
    items:
    - description: >
        <h3>Resources</h3>

  - classname: devsite-landing-row-cards
    items:
    - heading: "See MinDiff applied on a text classification model"
      image_path: /resources/images/tf-logo-card-16x9.png
      path: "https://developers.google.com/machine-learning/practica/fairness-indicators?utm_source=github&utm_medium=github&utm_campaign=fi-practicum&utm_term=&utm_content=repo-body"
      buttons:
      - label: "Check out the notebook"
        path: "https://developers.google.com/machine-learning/practica/fairness-indicators?utm_source=github&utm_medium=github&utm_campaign=fi-practicum&utm_term=&utm_content=repo-body"

    - heading: "MinDiff on the TensorFlow blog"
      image_path: /resources/images/tf-logo-card-16x9.png
      path: https://blog.tensorflow.org/2019/12/fairness-indicators-fair-ML-systems.html
      buttons:
      - label: "Read on the TensorFlow blog"
        path: https://blog.tensorflow.org/2019/12/fairness-indicators-fair-ML-systems.html

    - heading: "Model Remediation Library on GitHub"
      image_path: /resources/images/github-card-16x9.png
      path: https://github.com/tensorflow/model-remediation
      buttons:
      - label: "View on GitHub"
        path: https://github.com/tensorflow/model-remediation
